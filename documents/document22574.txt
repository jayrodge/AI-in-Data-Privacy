Understanding Privacy Policies: Content, Self-Regulation, and Market Forces
Florencia Marotta-Wurgler1 NYU Law School October, 2015
Abstract: Policymakers are constantly considering whether the current regulatory model of "Notice and Choice" of consumer information protection should be revised or whether bounds should be placed on firms' privacy information practices. Created by the Federal Trade Commission, Notice and Choice relies on the market-based approach of voluntarily disclosure of privacy practices and adherence to fair information practices though selfregulation to generate desirable information practices. This article offers a comprehensive empirical examination of 261 privacy polices across seven different markets to understand the content of these policies, evaluate the effectiveness of the current approach, and explore differences in privacy practices across markets. I study online privacy policies for seven markets that often raise privacy concerns: adult, dating, social networking, message boards, news and reviews, cloud computing, and gaming. For policies in the sample, I track specific terms pertaining to notice, data sharing, enforcement, security, and other relevant features. The analysis provides a window on modern privacy policies; the results call into question the efficacy of specific Notice and Choice regimes and their general potential. They also reveal striking market differences. One policy conclusion that emerges is that disclosure is unlikely to be effective: modern privacy policies are often vague or are silent on critical points. Another implication is that proposed solutions might need to be more nuanced and take into consideration the information privacy practices and firm incentives within each particular markets
1 New York University School of Law. I would like to thank Daniel Svirsky and Robert Taylor for outstanding work on the project, Oren Bar-Gill, Kevin Davis, Chris Hoofnagle, Kirsten Martin, Helen Nissembaum, Katherine Strandburg, Ira Rubinstein, Jeff Wurgler, Kathryn Zeiler, participants at the Privacy Law Research Scholars Conference, NYU Law Summer Workshop, 2014 Conference of Empirical Legal Studies Conference, University of Houston Law Center Faculty Workshop, Boston University Law and Economics Workshop, members of the Privacy Research Group at New York University for helpful comments and suggestions, and Conference of Empirical Legal Studies 2014 participants for comments on an earlier version of this paper. I would also like to thank Amanda Conley, Nicolas Heliotis, Julienne Markel, Isaac Sasson, Luke Smith, Melissa Quartner, Christopher Van Zele, and JingJing Wu for outstanding research assistance.

Introduction
Billions of people use the Internet every day to read the news, check email,
connect with friends on social networks, buy groceries, to use a search engine to answer a
particular question or find a site or document, and so on. Every keystroke and mouse-
click flows into a stream of information on that individual's characteristics, needs, wants,
and life. Companies can and often do collect this information for commercial purposes
such as constructing user-specific profiles to target content or advertising or to share with third parties.2
In light of the evidence that consumers care about their information privacy and of the potential costs associated with the unknown uses or leaks of such information,3
policymakers are constantly considering whether the current regulatory model of
consumer information protection should be revised and whether bounds should be placed on the collection, use, and security of personal information.4 For the most part, consumer
information has been protected by a self-regulatory regime articulated by the Federal
Trade Commission (FTC) that has generally been referred to as "Notice and Choice" and is predominantly based on disclosure.5 In essence, it asks that companies adopt privacy
policies explaining their practices related to the collection, use, sharing, and security of
consumer information, and that they adopt a subset of substantive "Fair Information Practices" (FIPs) through self-regulation.6
2 Tal Zarsky, Transparent Predictions, Ill L. Rev. 1503 (2013). 3 See Section I.A for a detailed account. 4 See, e.g.. Data Broker Transparency and Accountability Act, S. 2025 (2014); Data Security and Breach Notification Act of 2014, S. Cybersecurity Act of 2013. S. 1976, (2014); 1353, 113th Congress (20132014); Personal Data Privacy and Security Act of 2014, H. R. 3990 (2014); Geolocational Privacy and Surveillance Act, H. R. 1312 (2013); Email Privacy Act, H. R. 1852 (2013); Location Privacy Protection Act of 2014, S. 2171 (2014); Eliminate Privacy Notice Confusion Act, H. R. 749 (2013); Alexis Agin Identity Theft Protection Act of 2013, H. R. 2720 (2013). 5 See Ben-Shahar and Schneider, More than you Wanted to Know, Princeton University Press (2014); Oren Bar-Gill, Seduction by Contract (Oxford University Press, 2013). There are also a number of state laws protecting information privacy in a number of context. See.e.g. Calif. Bus. & Prof. Code §§ 2257522578 (requiring website operators to post privacy policies describing their information practices); Conn. Gen. Stat. § 42-471 (requiring businesses who collect Social Security information in the course of their business to implement privacy protection policies); Minnesota Statutes §§ 325M.01 to .09 (requiring Internet Service Providers to keep certain information private); Nebraska Stat. § 87-302(14) (prohibiting firms from making false or misleading statements in privacy polices). 6 Federal Trade Commission, Privacy Online: A Report to Congress 7 (1998), http://www.ftc.gov/sites/default/files/documents/public_events/exploring-privacy-roundtable-series/priv-
2

The goal of disclosure is to encourage firms to "compete on privacy" by allowing
consumers to become informed (either by reading policies or relying on third party
certification seals) and visit firms with desired information protection practices. 7 In
theory, disclosure can alleviate market failures that stem from asymmetric information
while preserving consumer choice. The reality of disclosure can be more complicated,
however, and Notice and Choice has been harshly criticized as ineffective.8 Indeed, early
evidence revealed that for the most part, companies failed to embrace the first set of
FTC's fair information practice principles, and a number of industry-wide initiatives,
such as seals, closed down after a few years of operation or become subject to industry
capture.9 Further, while privacy policies have been widely adopted, they have been found
to be long and hard to read.10
Despite the early setbacks, current approaches, both at the state and federal level,
continue to embrace disclosure-based solutions (combined with more substantive
protections) and self-regulation to protect consumer information privacy. The most recent
effort is the 2012 FTC Report to Congress, Protecting Consumer Privacy in an Era of
Rapid Change.11 The report encourages firms to adopt simplified and clear disclosures in
their privacy policies to lower the costs of becoming informed, offer consumers choices
for the collection and sharing of some information to enable them to control how their
23a_0.pdf. California law also requires that firms adopt privacy policies giving notice of their privacy practices. See CAL. Bus. & PROF. CODE §§ 22575-22577 (West 2008). 7 Id. 8 See, e.g., Ryan Calo, Against Notice Skepticism in Privacy (and Elsewhere), Notre Dame L. Rev., 87 (3) 2013. Paul Schwartz, Internet Privacy and the State, 32 Conn. L. Rev. 833 (2000); Jerry Kang, Information Privacy in Cyberspace Transactions, 50 Stan. L. Rev. 1193; Fred Cate, The Limits of Notice and Choice, 8 IEEE SEC. & PRIVACY 59, 59-62 (2010). ); Kirsten E. Martin, Transaction Costs, Privacy, and Trust: The Laudable Goals and Ultimate Failure of Notice and Choice to Respect Online Privacy. First Monday, Vol. 18, 12-2, 2013. M 9 See , e.g., Chris Jay Hoofnagle, Privacy Regulation: A Decade of Disappointment (2005), available at http://epic.org/reports/decadedisappoint.html. Mary Culnan, Protecting Privacy Online: Is Self-Regulation Working? J. Pub. Pol. and Mtng., 19 (1) (2000); See Robert Gellman & Pam Dixon, Many Failures: A Brief History of Privacy Self-Regulation in the United States (2011) (summarizing studies suggesting that industry's early self-regulatory initiatives failed) available at http://www.worldprivacyforum.org/wpcontent/uploads/2011/10/WPFselfregulationhistory.pdf. 10 See, e.g., Alicia McDonald and Lorrie Cranor, The Cost of Reading Privacy Policies, J. of Law and Pol. for the Information Society (2008) (estimating that it would take an average 244 hours per year for each individual to read the privacy policies of each web site visited once a month for a total cost of $3,534 a year). Allyson W. Haynes, Online Privacy Policies: Contracting Away Control Over Personal Information?, 111 Penn. St. L. Rev. 587 (2007). 11 Federal Trade Commission, Protecting Consumer Privacy In an Era of Rapid Change, available at https://www.ftc.gov/sites/default/files/documents/reports/federal-trade-commission-report-protectingconsumer-privacy-era-rapid-change-recommendations/120326privacyreport.pdf.
3

information is used, and to adopt a number of substantive protections through a continued embrace of self-regulation. The view is that the threat of more intrusive regulation should give firms enough incentives to comply with the current regime.12
For the current Notice and Choice regime to be effective, several conditions must be met. First, the privacy policies must communicate company information practices to individuals--or, more likely, intermediaries-- in a manner that would enable individuals to make informed choices. Second, companies must offer consumers clear and easy to use ways of exercising control of their information. In addition, firms must follow the substantive FIPs in the most recent FTC guidelines.. Of course, consumers must read this information and act on it in a way that improves their wellbeing.
Survey and experimental evidence on individuals' comprehension and attitudes towards information privacy present additional hurdles to the market approach. These studies find that consumers often lack information to make decisions regarding their information privacy, but, even with full information behave in ways inconsistent with with their stated preferences. 13 The tradeoffs associated with the sharing of personal information are often complicated, as they are often context-specific and bundled with other products or services, and possibly hamper individuals' ability to use the information received to make welfare maximizing choices. An implication of these findings is that even if firms fully comply with the Notice and Choice regime, it is possible that market forces will not generate optimal information privacy practices.
This paper examines empirically the extent to which the Notice and Choice model, as most recently articulated in the FTC report to Congress, has achieved some of its main goals by evaluating the degree of compliance with information privacy guidelines across and within seven markets for the sample firms. In doing so, it also offers a detailed and systematic description of the content of privacy policies by examining terms that comprise a number of relevant information privacy guidelines. Next, it explores the possibility of market effects by examining compliance and information privacy protection across markets. The results offer some evidence on the relative success of Notice and

12 See Peter P. Swire, Markets, Self-Regulation and Government Enforcement in the Protection of Personal

Information, in PRIVACY AND SELF-REGULATION IN THE INFORMATION AGE 3 (U.S.

Department

of

Commerce

ed.,

1997),

available

at

http://www.ntia.doc.gov/reports/privacy/selfreg1.htm#1A.

13 See Section

4

Choice, present a systematic analysis of the content of privacy policies, and inform existing debates regarding the desirability of disclosure and self-regulation in consumer markets.
Specifically, I study the content of the privacy policies of 261 firms from seven online markets where people often share personal and personally identifiable information (albeit to different degrees)--adult sites, social networks, dating sites, cloud computing, gaming sites, news and reviews, and forum/special interest sites. These are services where consumers actively provide private information, or provide highly sensitive information, and thus more likely to know or care about the companies' information practices. Given their characteristics, these services' privacy policies make for an interesting and potentially revealing sample.
I graded policies on 49 terms related to categories that commonly appear in privacy policies and which are referenced in the most recent FTC guidelines as well as other relevant guidelines. The categories relate to notice regarding the collection, use and sharing of information, consumer access to data and control of information, data security, data practices, enforcement, and company adoption of substantive privacy protection measures ("privacy by design," as labeled by the FTC).
I use the graded terms to measure the content of each policy against the guidelines outlined in the FTC 2012 Report to Congress to estimate the degree of firms compliance. A number of self-regulatory frameworks are possibly guiding the content of privacy policies, so I present additional measures of compliance with relevant guidelines. To account for the possibility that companies are sluggish in updating their policies, I measure the extent to which the sample contracts comply with earlier FTC guidelines, outlined in a 2000 FTC Report to Congress. A number of sample firms operate within the European Union (EU) and must comply with the EU Data Directive. I account for this by analyzing the extent to which to the companies comply with the US-EU Safe Harbor Framework, a self-certification program operated by the Department of Commerce designed for companies who seek to comply with the privacy standards of the EU. Finally, to get a more comprehensive sense of current information privacy practices, I measure the extent to which the policies comply with two other relevant guidelines, the1973 Report by the Department of Health, Education and Welfare (which provide the
5

basis of the FTC's guidelines) , and concurrent 2012 White House Consumer Privacy Bill of Rights, a blueprint for proposed legislation which incorporates many of the principles outlined in the FTC guidelines.14
The results suggest that Notice and Choice hasn't resulted in privacy policies capable of effectively informing consumers and giving them control of their information. First, privacy polices are long: 2,227 words on average. Yet despite their length, they are often silent on important categories (thus failing the FTC's requirement that companies disclose their information practices in detail), making it impossible to know how information is collected and used. Silence is problematic in this context because there are no clear gap-filling default rules, such as those of Article 2 of the UCC. While there is some guidance from judicial opinions and FTC enforcement actions under Section 5 of the FTC Act, these mostly address companies' failure to comply with explicit commitments made in their privacy policies and are thus unlikely to be informative about the meaning of contractual silence.15
When terms are included, they are written in language that is often vague or ambiguous. For instance, almost all contracts use terms such as "affiliates" or "third parties" when discussing the recipients of shared information, but only 7% define them. Policies also include contradicting statements and ill-defined actions. These features, when combined, make understanding the terms a challenging endeavor. Indeed, coding the terms in this sample often times resulted in disagreement among individuals with legal training, some quite extensive.
An evaluation of compliance with self-regulatory guidelines more generally leads to similar results. The majority of firms tend to comply with 20% to 40% of the requirements of the 2012 FTC guidelines, even though preliminary reports have been circulating since 2010. This includes failure to comply with substantive protections that
14 See U.S. DEP'T OF HEALTH, EDUC., & WELFARE, RECORDS, COMPUTERS, AND THE RIGHTS OF CITIZENS: REPORTS OF THE SECRETARY'S ADVISORY COMMITTEE ON AUTOMATED PERSONAL DATA SYSTEMS (1973); The White House, Consumer Data Privacy in a Networked World: A Framework for Protecting Privacy and Promoting Innovation in the Global Digital Economy, available at https://www.whitehouse.gov/sites/default/files/privacy-final.pdf. This later evolved to the Consumer Privacy Bill of Rights, available at https://www.whitehouse.gov/sites/default/files/omb/legislative/letters/cpbr-act-of-2015-discussiondraft.pdf. 15 15 U.S.C. § 45. For a full discussion of the FTC jurisprudence, see Daniel Solove and Woodrow Hartzog , The FTC and the New Common Law of Privacy, 114 Colum. L. Rev. 583 (2014).
6

go beyond disclosure. Compliance with the US-EU Safe Harbor Agreement is similarly weak. Among firms who claim to adhere to the US-EU Safe Harbor, over two-thirds comply with only up to 40% of the requirements that can be ascertained by reading the privacy policy. These results offer a sobering assessment of current regulatory approaches and invite us to consider techniques that move beyond increased disclosure and self-regulation.
Compliance varies by market, however. Adult and cloud computing sites are more likely to comply with the FTC benchmarks. Specifically, adult sites are 23% more likely than firms in other markets to comply with the notice requirements, meaning that the policies are more likely to offer detailed descriptions of the ways in which the information will be collected, shared, or used. These sites are also 31% more likely than sites in the other markets to comply with the FTC's data sharing guidelines, which impose constraints on how and when the information should be shared. Cloud computing sites are 21% more likely than firms in other markets to comply with the requirements of data security. They are also 30% more likely than other firms to implement substantive information protection practices throughout their organization ("privacy by design"). Gaming and special interest markets do considerably worse than other markets in a number of dimensions, and are both 5% less likely to comply with the guidelines. The results are statistically significant and hold when controlling for site popularity, company size, and whether the service is free or requires payment.
Further exploration of privacy protection across markets reveal similar patters, suggesting some persistent market differences. For each contract, I create a grade that measures the degree to which the 49 terms in each policy favor consumer privacy. A term will be deemed to be protective if it articulates its data collection practices and such practices include collection and sharing to the minimum extent, user control to the maximum extent, and relatively more security, and so on for each category of terms. The scores for each term are then added and weighed by their level of important using the information privacy benchmarks, thus allowing for an easy comparison across firms. This measure does not represent a normative baseline nor is intended to reflect consumer preferences. More privacy is not always optimal for the consumer. Rather, this measure provides an alternative way of comparing information protection across firms and
7

markets. This measure shows that the privacy polices of adult sites and cloud computing are more "protective" in a number of dimensions, relative to other markets. Adult sites have comparatively more detailed notices, claim less information collection, state limited uses (such as only to process payment transactions) and minimal sharing, and offer relatively more security. Cloud computing sites impose relatively more restrictions on the number of affiliated entities and employees who have access to the data, claim to implement substantive security protections, identify means of security protection (such as encryption), and more likely to implement privacy by design measures, as stated above.
These results make intuitive sense: given the potential negative repercussions created by the public disclosure of users' association with adult sites, users of such sites might be particularly concerned with some of the firms' information privacy practices. Similarly, users of cloud computing services, which include business users trusting such firms with valuable information, might be especially concerned with data breaches and the disclosure of the content of their files. Firms in both markets might attenuate those concerns by offering stronger protections. The results hold when controlling for firm and service characteristic, including whether it is offered free or for a price. I also find that older, larger, and more popular firms are more likely to offer policies with more substantive protections. In contrast, firms in dating, gaming, and news and reviews sites, fare relatively worse than firms in other markets in a number of dimensions.
While these findings cannot prove whether consumers care especially about information privacy protection in the adult and cloud computing markets, or whether the absolute level of protection offered (even if relatively better than other markets) is optimal, the findings suggest that-assuming that protecting information is costlier than not protecting it-- firms in such markets behave as if consumer care about particular information practices.
The paper makes three contributions. First, it evaluates whether firms have embraced current Notice and Choice disclosure regulation as well as against a number of meaningful frameworks as measured by the content of their privacy policies evaluates such practices. Second, it offers a snapshot of current information privacy practices from a wide range of firms in seven markets where information sharing is pervasive, albeit to
8

different degrees. Finally, it offers an analysis of privacy protections by firms across and within markets to show a richer picture of information privacy practices.
The evidence suggests that Notice and Choice disclosure regulation is failing. Policies are long, complex, ambiguous, incomplete, and often silent on important matters. These features make it impossible to understand them and for intermediaries to digest them in a consumer-friendly manner. That being said, there are differences in compliance across markets that regulators might want to explore further and take into consideration when thinking about consumer information privacy protection regimes.
While the study offers a rich analysis of the effectiveness of Notice and Choice, it has a number of limitations. First, it cannot examine company practices beyond those disclosed in privacy policies. To the extent these differ, this would limit the conclusions of the analysis. Second, the finding that companies have for the most part failed to adhere to the current information privacy framework does not necessarily imply that there is a market failure. There are some differences in compliance and protection across markets that merit further studies. In addition, policies might spell onerous practices but might nonetheless be constrained by alternative disciplining mechanisms, such as reputation or enforcement actions under the FTC's "Unfair and Deceptive Practices" Act. Finally, as noted earlier, even if companies comply with all disclosure requirements, it is not clear that compliance will induce consumers to read, understand, and act on the information conveyed by firms. Compliance with substantive protections, however, might increase consumer protection. The welfare implications of such compliance are difficult to ascertain without information about costs and consumer preferences.
The paper proceeds as follows. Section I offers a brief overview of the laws governing consumer information privacy online. Section II provides background on the current literature of privacy policies and self-regulation. Section III explains the sample and methodology. Section IV presents the compliance analysis. Section V presents the information protection analysis across markets. Section VI discusses the implications of the results and concludes.
I. Background
9

A. Consumer Attitudes Towards Information Privacy and Privacy Policies
Many individuals today share information with others with apparent comfort and ease.
People post updates on social networks, display their employment credentials on
LinkedIn for networking purposes, and are happy to receive movie recommendations that
Neflix produces by analyzing past movie choices. Individuals have also embraced the
convenience of online commerce and the highly dynamic world of mobile applications
that offer a wide variety of useful services and information. Most of these entities collect,
use, and share their personal information with others, including third parties unrelated to
the transaction or services.
A first order question in debates regarding the protection of information privacy
has been whether individuals actually care about it. Evidence suggests that they do.16
Consumers are reluctant to share information with third parties in a variety of contexts
and believe that the information on their mobile phones is private. 17 Laboratory
experiments have shown that in some settings consumers are willing to pay to protect
their private information from being disclosed. 18 Moreover, there is evidence that
consumers are imperfectly informed about information practices and have only a limited
16 See, e.g., PEW Survey, Privacy, Anonymity, and Security Online, September 5, 2013, available at http://www.pewinternet.org/2013/09/05/anonymity-privacy-and-security-online/ (finding that 68% of respondents believe that current laws are not adequately protecting information privacy online and 50% are concerned about the amount of information about them is available online); Hoofnagle, C.J., King, J., Li, S., & Turow, J. (2010). How different are young adults from older adults when it comes to information privacy attitudes and policies? Available at http://ssrn.com/abstract=1589864 (reporting representative telephone survey results of 1,000 individuals in the U.S. showing that younger adults have similar privacy concerns and desires of information protection as older adults). See also, Marthews, Alex and Tucker, Catherine, Government Surveillance and Internet Search Behavior (April 29, 2015). Available at http://ssrn.com/abstract=2412564 (finding a significant and measurable impact on users' Google search behavior after the Snowden revelations, revealing how surveillance affects consumer behavior). 17 See e.g., P. G. Leon, B. Ur, Y. Wang, M. Sleeper, R. Balebako, R. Shay, L. Bauer, M. Christodorescu, and L. F. Cranor (finding that 50% a sample of 2,912 survey participants on a medical website would be unwilling to share any information when asked about it, and that factors such as the scope of use and data retention period affected individuals' decision to share personal information with the site.); Jennifer M. Urban, Chris Jay Hoofnagle, and Su Li, Mobile Phones and Privacy, Jul. 11, 2012, available at http://ssrn.com/abstract=2103405 (surverying 1,200 individuals and finding that most consider information in their phones to be private and reject information collection by content providers and third party vendors.); Avi Goldfarb & Catherine Tucker, Shifts in Privacy Concerns, American Econ. Rev. (2010) (examining over three million responses over eight years and finding increased reluctance to share information over time). 18 Janice Y. Tsai, Serge Egelman, Lorrie Cranor, Alessandro Acquisti, The Effect of Online Privacy Information on Purchasing Behavior: An Experimental Study, 22 INFO. SYS. RES. 254 (2007).
10

understanding of how information collected by vendors will actually be used, highlighting the need for increased or improved information.19
Yet, a number of studies reveal that consumers also appear to have difficulty
understanding the costs associated with giving away private information and that privacy preferences are susceptible to context and framing. 20 This is hardly surprising: the
tradeoffs associated with the sharing of personal information are often complicated, as
they are often context-specific and bundled with other products or services, and possibly
hamper individuals' ability to use the information received to make welfare maximizing choices.21 A natural implication of these findings is that even full compliance by firms
with the Notice and Choice regime might not enable market forces to help generate
optimal information privacy practices.
B. A Disclosure and Control Based Approach
With the exception of area specific statutes and some state laws, 22 consumer
information privacy protection in the United States is primarily based on disclosure, user
19 See, e.g., Alessandro Acquisti and Jens Grossklags, Privacy and Rationality in Individual Decision Making, 3 SECURITY & PRIVACY 26 (2005) (using a survey to find that consumers claim to value privacy highly, for monetary and non-monetary reasons, and that consumers would welcome government intervention to protect privacy). See also Hoofnagle et at, infra (showing that individuals answered questions related to firm information privacy practices incorrectly). 20 See, e.g., Alessandro Acquisti & Ralph Gross, Imagined Communities: Awareness, Information Sharing, and Privacy on the Facebook in Privacy Enhancing Technologies in PRIVACY ENHANCING TECHNOLOGY (2006) (finding that Facebook users care a lot about privacy but are unaware of Facebook's privacy policies or hold incorrect beliefs about Facebook's policy); Joseph Turow, Chris Jay Hoofnagle, Deirdre Mulligan, Nathaniel Good, & Jens Grossklags., The Federal Trade Commission and Consumer Privacy in the Coming Decade, 3 I/S: J. L. & POL'Y FOR INFO. SOC'Y 723, 729­32 (2007­08) (collecting survey evidence revealing that consumers worry about online privacy and that consumers believe privacy policies are meant to protect them); Alessandro Acquisti, Leslie K. John and George Loewenstein, What is Privacy Worth? J. Legal Stud. 42(2) 249-74 (2103) (showing that privacy valuations are extremely context dependent and concluding that despite this, individuals care about privacy.); See Chris Jay Hoofnagle & Jennifer King, What Californians Understand about Privacy Online (2008) ("In a way, consumers interpret privacy policy as a quality seal that denotes adherence to some set of standards.") available at http://ssrn.com/abstract=1262130. 21 Acquisti & Grossklags, id. 22 While Congress enacted laws regulating information privacy in particular sectors, states, in particular California, have been actively innovating on the information privacy front. For example, California's Data Breach Notification Law of 2002 became a model for other states, most of which followed suit. CAL. CIV. CODE §§ 1798.29, 1798.82. California also enacted the California Privacy Protection Act, which entitles consumers to find out how their personal information is shared by companies for marketing purposes and also encourage companies to allow consumers to opt-out of such sharing. CA Civil Code § 1798.83 (2003). Other states, such as Nebraska and Pennsylvania, enacted laws prohibiting companies from making false or misleading statements in their privacy policies. Nebraska Stat. § 87-302(1); 18 Pa. C.S.A. §4107(a)(1).
11

control, and self-governance. 23 The Notice and Choice model is loosely based on the 1973 department of Housing, Education, and Welfare Fair Information Practices (HEW FIPs), which became the foundation of many information privacy law and regulations. The HEW FIPs require notice on the collection and use of data, and grant subjects the right to control uses of data beyond the purposes for which they are obtained, among other requirements.24
In the mid-nineties, the FTC implemented this market-driven approach by encouraging firms to adopt privacy policies outlining their information practices, obtain consent from consumers for uses of information extending beyond the original collection purpose, and embrace fair information practices through self-regulation.25 The guidelines outlined four additional principles: access, security and enforcement. Specifically, "access" requires companies to provide individuals access to their own data and an opportunity to correct mistakes. "Security" requires that entities take reasonable steps to adequately protect the information collected. "Enforcement" requires the adoption of a mechanism capable of providing sanctions for non-compliance. Howard Beales, former Director of the FTC Bureau of Consumer Protection, explained Notice and Choice as follows: "First, privacy notices should be viewed as a means of facilitating competition over privacy practices. Their goal should be to help consumers understand what information is collected about them and what is done with that information, not to simply scare consumers into opting out of information sharing."26
Despite widespread adoption of privacy policies, there was a general dissatisfaction with Notice and Choice.27 A 2010 FTC preliminary report to Congress stated that"[t]he Notice and Choice model, as implemented, has led to long,
23 FTC, Privacy Online: A Report to Congress, available at http://www.ftc.gov/sites/default/files/documents/reports/privacy-online-report-congress/priv-23a.pdf. 24 The eight principles are collection limitation, data quality, purpose specification, use limitation, security safeguards, openness, individual participation, and accountability. HEW Principles, supra note .__. 25 See FTC, Privacy Online, Report to Congress 1998, available at http://www.ftc.gov/sites/default/files/documents/reports/privacy-online-report-congress/priv-23a.pdf. 26 Howard Beales, Dir., Bureau of Consumer Prot., Remarks on the Privacy Notices and the Fed. Trade Comm'n's 2002 Privacy Agenda (Jan. 24, 2002), (transcript available at https://www.ftc.gov/publicstatements/2002/01/privacy-notices-and-federal-trade-commissions-2002-privacy-agenda) 27 For a review of the failure of codes of conduct and privacy seals, see Robert Gellman and Pam Dixon, Many Failures: A Brief History of Privacy Self-Regulation in the United States, (Oct. 14, 2011) available at http://www.worldprivacyforum.org/wpcontent/uploads/2011/10/WPFselfregulationhistory.pdf.
12

incomprehensible privacy policies that consumers typically do not read, let alone understand." 28 The fate of Notice and Choice is not uncommon; other forms of disclosure regulation have been found to be similarly unsatisfactory.29 The report also expressed a similar dissatisfaction with the effectiveness of the market in supplying an adequate information privacy framework: "industry efforts to address privacy through self-regulation have been too slow, and up to now have failed to provide adequate and meaningful protection."30
In reaction to this, the FTC urged Congress to enact legislation setting forth a basic level of privacy protection for commercial web sites that collect personally identifiable consumer information. Yet in its most recent report to Congress in 2012, Protecting Consumer Privacy in an Era of Rapid Change, the FTC insisted on disclosure by urging firms to make their disclosures clear and conspicuous, without conflicting or internally contradictory language. In addition, it recommended that firms offer a summary of their information practices, called "layered notice," at the top of their privacy policy.31 The report also included substantive recommendations, such as asking firms to adopt "privacy by design;" that is, take business decisions that are mindful of consumer privacy throughout their business operations. 32 Privacy by design requires firms to limit data collection and retention, adopt reasonable security and data accuracy measures, and implement data management procedures.33
Also in 2012, due to increased awareness to consumer information privacy, the Obama administration released a report, Consumer Data Privacy in a Networked World, where it urged for the adoption of legislation that would create baseline privacy

28 FTC Staff Report, Protecting Consumer Privacy in an Era of Rapid Change, supra note __.

29 See Omri Ben-Shahar & Carl Schneider, supra note 5 (for a thorough review of the failures of mandated

disclosure); Florencia Marotta-Wurgler, Will Increased Disclosure Help? Evaluating the Recommendations

of the ALI's "Principles of the Law of Software Contracts," 78 U. Chi. L. Rev. 165 (2011).

30 Preliminary FTC Report, Protecting Consumer Privacy in an Era of Rapid Change: Recommendations

For

Businesses

and

Policymakers,"

2010,

available

at

https://www.ftc.gov/sites/default/files/documents/reports/federal-trade-commission-bureau-consumer-

protection-preliminary-ftc-staff-report-protecting-consumer/101201privacyreport.pdf.

31 See, FTC "Protecting Consumer Privacy in an Era of Rapid Change: Recommendations For Businesses

and Policymakers," Report to Congress 2012, [hereinafter FTC 2012 Report] available at

http://www.ftc.gov/news-events/press-releases/2012/03/ftc-issues-final-commission-report-protecting-

consumer-privacy.

32 Id.

33 The report also recommended the implementation of a "Do Not Track" mechanism allowing consumers

to control the collection of their data. Id.

13

protection standards. The report also encouraged self-regulation through the adoption of voluntary codes embracing the FTC FIPs and a disclosure-based approach.34
While a number of privacy bills were introduced in Congress in the wake of the report, none made it into law.35 A number of new bills wait in Congress and several state legislatures, fates pending.36 For the time being, the protection of consumer information privacy is still within the domain of the Notice and Choice regime.
II. Prior Empirical Literature
As noted earlier, privacy policies have been at the center of Notice and Choice model of consumer protection. Studies have found them to be long and at a linguistic complexity typically requiring at least two years of college to fully grasp.37 Indeed, it has been estimated that it would take individuals about 201 hours a year to read all the privacy policies of the sites they visited.38 It is thus not surprising that people don't read them.39 Privacy notices themselves have also been found to confuse consumers.40
Early evidence suggests that companies have also failed to adopt FIPs. In a report based on the work by Mary Culnan, entitled Privacy Online: Fair Information Practices in the Electronic Marketplace in 2000, the FTC reported the findings from a study of 100 privacy policies that about 20% to 40% complied with FIPs.41The report employed a generous notion of compliance (i.e., the notice requirement would be met if the privacy

34 FTC 2012 Report, White House Consumer Privacy Bill of Rights.

35 See, e.g., Sen. Leahy Personal Data Privacy Act of 2009 (S. 1490); Sen. Feinstein, Data Breach

Notification Act of 2009 (S. 139); Kerry-McCain, The Commercial Privacy Bill of Rights of 2011 (S. 799),

Franken-Blumenthal, The Location Privacy Protection Act of 2011 (S. 1223).

36 CITE

37 C. Jense & C Potts, Privacy Policies as Decision-Making Tools: an Evaluation of Online Privacy Notices.

SIGCHI. 2004. Xinguang Sheng and Lorrie Faith Cranor, Evaluation of the Effect of U.S. Financial

Privacy Legislation Through the Analysis of Privacy Policies, 2 INFO. SCI. J. OF L AND POL'Y 943 (2005)..

38 McDonald and Cranor, The Cost of Reading Privacy Policies (estimating that it would take individuals

about 201 hours a year to read all the privacy policies of the sites they visited) (2008).

39 Privacy Leadership Initiative. Privacy Notices Research Final Results, November 2001, Available at:

http://www.und erstandingprivacy.org/ content/library/datasum.pdf.

40 Chris Jay Hoofnagle & Jennifer Urban, Alan Westin's Privacy Homo Economicus, 49 Wake Forest L.

Rev. 261 (2014); Turow, J. Feldman, L., and Meltzer, K. Open to Exploitation: American Shoppers Online

and

Offline.

The

Annenberg

Public

Policy

Center.

2005.

http://www.annenbergpublicpolicycenter.org/NewsDetails.as px?myId=31.

41 See Culnan, Mary J. (1999), Georgetown Internet Privacy Policy Survey: Report to the Federal Trade

Commission, available at http://www.msb.edu/faculty/culnanm/gippshome.html.

14

policy disclosed at least some information collected from the individual, not all of it). It also found that firms did not adhere to voluntary codes, such as privacy seal certification programs, as much as originally desired.
A 1999 study by EPIC tracked ten terms in the 100 most popular sites and found weak compliance with current FTC guidelines.42 More recently, a study examining the standardized privacy policies of thousands of financial institutions using a machine learning approach found that very few comply with the requirement of the GrammLeach-Bliley Act, a statute mandating particular disclosure of financial information by specific financial institutions.43
This study builds on and improves this literature in a number of ways. First, it offers the first empirical analysis examining compliance with the most recent FTC guidelines. Second, it measures compliance with other relevant privacy guidelines, thus offering a more comprehensive view of firms' privacy practices (as explained in their privacy policies). Third, it develops a methodology creating replicable benchmarks against which to measure compliance. Fourth, it analyzes and compares privacy practices and information protection across and within seven different and important markets that haven't been analyzed systematically and compared before, revealing interesting differences. Finally, the analysis covers a comprehensive set of terms that give a more complete picture to date on the content of privacy policies.
III. An Empirical Analysis of Privacy Policies
The existing empirical literature provides a colorful picture regarding consumer attitudes towards information privacy and ability to make information privacy trade-offs that present some challenges to the success of a disclosure-based market approach. However, absent more complete information about the relative costs and benefits of
42 See Surfer Beware III, available at https://epic.org/reports/surfer-beware3.html an discussed in Chris Hoofnagle (2005) http://epic.org/reports/decadedisappoint.html. 43 Cranor et al, Examining Thousands of Privacy Polices of Financial Institutions. (2015). See also Michael Birnhack and Niva Elkin-Koren, Does Law Matter Online? Empirical Evidence on Privacy Law Compliance, 17 MICH. TELECOMM. TECH. L. REV. 337 (2011) (conducting an empirical examination of compliance with Israeli information privacy laws by examining the privacy practices of 1360 active websites and finding low levels of compliance)
15

information collection and sharing, as well as actual consumer and firm behavior in regards to information privacy online (and alternative disciplining mechanisms), it is difficult to establish whether the market for personal information online is working well or requires some form of intervention. We can, however, evaluate whether current approach designed to protect consumer information online are being complied with and investigate market differences to uncover any possible market effects. I focus on five different benchmarks.
As noted earlier, the FTC has been at the forefront of information privacy protection in the United States. Together with some state laws and the work of state attorneys general, the FTC has filled in the gap left by the patchwork of information privacy laws in the US. Consequently, the main focus of the analysis is the extent to which firms embrace the guidelines outlined in the 2012 FTC Report to Congress. Yet these guidelines don't exist in a vacuum. Contemporaneously with the release of the FTC 2012 Report, the Department of Commerce proposed a Consumer Privacy Bill of Rights embracing many of the principles of the FTC report. For comparative purposes, I also measure the extent to which firms comply with the Bill of Rights. Although the data used in this study were gathered in June 2013, both reports have been available as early as 2010, thus giving firms time to adopt the new principles.
The third measure of compliance used derives from an earlier standard, the FTC Guidelines from its 2000 report to Congress to account for the possibility that firms might be sluggish in updating their policies. A number of companies operating beyond the United States might have to comply with other self-regulatory standards. For this reason, I also track the extent to which firms comply with the provisions of the US-EU Safe Harbor. This should offer a more comprehensive account of compliance with selfregulatory standards.
Finally, I measure the extent to which privacy policies comply with the 1977 HEW FIPs, which that has been model for the FTC regimes. In the absence of clear default rules, this analysis should help us understand current privacy practices against well-established standards.
A. Methodology and Sample
16

The sample firms are in seven online markets where consumers tend to share personal and sensitive information: adult, dating, social networks, message and special interest, cloud computing, news and reviews, and gaming. Not all markets are the same, of course. Individuals might share more information on dating and social network sites than on gaming and reviews sites. Sharing is also qualitatively different across markets; compare a social network with a cloud computing service, or with an adult site. I chose firms in markets where information sharing is salient and potentially extensive because consumers might be more likely to become aware of and care about the privacy policies of the firms with which they interact. With the exception of adult sites, cloud computing, and some games and news sites, the services offered by the sample firms are essentially generated by information shared by users of the sites. This also makes the privacy policy relatively more important. To the (unlikely) extent that consumers shop for firms with good privacy policies, we are more likely to find it here, where consumers are aware that they are sharing personal information and, in some cases, lots of it. In addition, other markets relate to activities that are generally perceived as highly private (in the case of adult sites), or involve potentially significant losses in the event of publish disclosure of information (in the case of cloud computing sites), and thus might lead consumers to take special care about the information practices of firms, which in turn might induce firms to offer better terms.
The sample includes 261 firms that conduct business in the United States. They are fairly diverse, and a small minority has greater markets abroad. They include giants like Facebook and Google, as well as dozens of smaller firms (such as veggiedate.com). The collection efforts attempted to encompass as many firms in each market as publicly available. An initial sample of 150 firms came from companies that were listed in Wikipedia in 2009, 2010, and 2011, as at the time of collection it contained a fairly extensive list for the sample categories.44 In 2010, I obtained 36 additional dating sites from the website www.100bestdatingsites.com, by selecting those active sites that catered to individuals in the United States. I obtained 55 additional bulletin board sites from
44 The list was originally available at http://en.wikipedia.org/wiki/List_of_social_networking_websites. Additional sites were collected as the arose.
17

http://rankings.big-boards.com/. I obtained 17 adult sites in June 2015, which include the largest sites that make up for majority of the market, from Alexa traffic rankings. To ensure the representativeness of the sample, I compared the firms in five markets (adult, social networks, cloud computing, dating, and games) against market share reports generated by IBISWorld, a research firm that specializes in industry research. The reports confirmed that the sample includes the top firms in each of the sample markets with a significant combined market share. I thus have little reason to believe that the firms obtained for the sample will create a substantial bias in the analysis of their privacy policies. The first half of Table 1 reports the summary statistics for each market. Of the 261 privacy policies, 17 are adult sites, 28 are cloud computing, 40 are dating sites, 23 are gaming sites, 18 are news and reviews sites, 89 are social networks, and 50 are special interest/message boards.
B. Firm Characteristics
The first half of Table 1 summarizes the company characteristics that might affect the content of privacy policies. About 4% of sample firms are not for profit, a characteristic that might decrease firms' interest in sharing personal information. Twenty seven percent of the sample firms are public, a proxy for size. Another relevant company characteristic is whether the product or service is offered for free or on a subscription basis, as those firms who earn money from subscriptions might have a decreased need to rely on the sharing of personal information as a source of revenue. About 40% of sample firms offer at least a portion of their services for a fee, but there are differences across markets. A little over 90% of dating sites, a little over half of cloud computing and gaming sites, and almost a quarter of all adult sites, are on a subscription basis. The remaining markets do not offer subscriptions but premium access, or offer the ability to purchase items for a price. These include 16% of social networks, 3% of message boards, and 28% of news and reviews sites. This last number is partly driven by firms like Amazon.com, who have review forums but also sell merchandise. There are very few firms that offer more than one product or service, so classification is generally easy.
18

Finally, I track the Alexa Rank from alexa.com, a website that creates rankings on web sites based on the number of monthly visitors and use these rankings as a proxy for company size.45 A lower number indicates a more popular site; the mean Alexa rank is 949,099 and the standard deviation is 3,766,538, indicating a large range in the amount of traffic our sample companies get.
While the sample firms' data were collected over years, the privacy policies used in this study were all collected in June 2013, thus offering a snapshot of privacy practices as of that time.46 The first variable, "Year Last Updated," measures the last reported date when the privacy policy was updated. Two hundred and nineteen firms include this information in the contract, so I report the "last update" for this subset. On average, contracts in force in June 2013 were last updated in 2011 (median 2012). Cloud computing firms had the most recently updated contracts, perhaps because this is a newer market. I track to measure whether companies who revise their contracts later are more or less likely to comply with the privacy guidelines or offer more or less protection.
IV. Evaluating the Effectiveness of Notice and Choice Regulation
A. Contract Characteristics and Notice
This sub-section explores whether particular contract characteristics, such as the length of the contract and whether the company adheres to a privacy certification seal, are likely to provide effective notice. These can be found in the second half of Table 1.
45 Alexa.com. Alexa rankings offer just approximate estimates of web traffic because they rely on the metrics provided by those users who install the Alexa Toolbar, which might not be representative of all internet users. Still, there is no reason to believe that the sample we use is particularly biased. Rankings might not be precise, but they are approximate enough to reveal a wide range of company sizes. 46 An exception is the adult sites, which were collected in June 2015. There is little reason to believe that much of the difference across markets is due to differences in collection dates, as comparative analysis of more recent polices reveal similar results. See Florencia Marotta-Wurgler and Daniel Svirsky, Who's Afraid of the FTC? An Analysis of the Effectiveness of "Unfair and Deceptive" Practices using Privacy Policies (working paper, 2015).
19

While there has been a recent push to standardize and shorten contracts (e.g., being considered in California47), existing guidelines prescribe no limit to contract length. The average length in our sample is 2,176 words long, approximately the average length of End User Software License Agreements. 48 Gaming and social networks have the longest contracts, with an average around 2,783 for gaming sites and 2,500 words for social networks. Like EULAs, privacy policies are long and take a while to read. Adult sites have the shortest contract of all, with an average of 1,356 words. Subsequent analysis will show that much of this difference is explained by adult sites' tendency to claim little collection and sharing, and to articulate relatively simply and clearly the firms' information practices.
The cost of reading could be reduced, though, if firms adopt certification seals that signal to consumers the quality of privacy policies without the need of reading them. One of the self-regulatory efforts has been to encourage firms to adopt codes of conduct in the form of privacy seals to adhere to particular frameworks. I track whether a particular firm affirms in its privacy policy that is adheres to a particular privacy seal, such as TRUSTe, or claim to adhere to a particular framework, such as the US-EU Safe Harbor. In this sample, 30% of the companies claim certification of adhere to a privacy seal or self-harbor agreement. There are wide differences across markets. The highest fraction of seal adherents comes from the cloud computing market, where 68% of firms claim to do so. Companies in this market might feel more pressure to do this because consumers' potential losses associated with the loss or leaking of uploaded information are large and because these companies may have larger businesses as clients, who might insist on certain security measures.49 Consistent with prior evidence, the take-up rate of privacy seals is to low to produce an informational advantage to consumers.50
47 See, e.g., AB 242 (proposing to amend California Online Privacy Protection Act to "require the privacy policy of a commercial Web site or online service to be no more than 100 words, be written in clear and concise language, be written at no greater than an 8th grade reading level.) 48 Marotta-Wurgler, What's in a Standard Form Contract? An Empirical Analysis of Software License Agreements. J. Emp. L. Studies (2007). 49 Of the 78 firms claiming to adhere to a benchmark or seal (unreported), 58 claim to adhere to the US-EU Safe Harbor and 25 to the US-Swiss Safe Harbor, which enable firms with a presence in the EU and Switzerland to comply with the EU laws' heightened standard. Sample companies claim to adhere to 14 other certification programs in the EU and Australia (such as United Kingdom Information Commissioner's Office and the Australian Best Practice Guidelines for Online Behavioral Advertising). 50 CITE
20

B. Correlations
Are there particular firm features that are associated with contract characteristics? This section explores the relationship (in the form of correlations) between contract and company characteristics. One would expect that larger firms, who have higher traffic and are likely to gather more information, would have higher incentives to innovate by finding new ways of using data, and thus would modify and update their privacy policies more frequently. The results in Table 2 support this view. Popular companies with lower Alexa rankings (i.e., higher traffic) are more likely to have updated their policies recently. Popularity is also associated with longer contracts and an increased likelihood of certification, a likely cause of the presence of in-house counsel and the pressures of reputational sanctions for failure to adhere to established guidelines. The results are similar for public held firms, who are also popular. Larger companies are also more likely to have a larger client base and thus adhere to safe harbor agreements. However, one might have instead imagined that smaller, less known firms would be willing to invest in a third party seal to increase consumer trust. Yet there is no evidence supporting this position, perhaps because consumers don't pay much attention to seals anyway so it might not be worth the expense.
C. Compliance with Notice and Choice: A Closer Look at Privacy Policies
For notice to be effective, the terms in the policies must be clear and privacy practices must be spelled out completely, especially since there are no default rules that can fill in gaps in the face of contractual silence. This sub-section evaluates the quality of notice in the privacy policies themselves by measuring the extent to which they comply with the disclosure mandates of various guidelines.
This and the subsequent analyses are done by tracking 49 terms that are relevant for the five aforementioned privacy guidelines. All contracts were read and graded by hand. Each contract was assigned to a team of eight law students, which was divided in pairs. To increase grading accuracy, each member of a pair read the entire contract and
21

graded a specific portion of it independently. Each contract was thus graded twice. The team of students and I would meet periodically to discuss any discrepancies in grading and decide on the proper classification. As the number of contracts graded, the number of discrepancies among graders decreased, but did not disappear. In fact, discussions over particular terms were usually long. This is because these contracts include ambiguous clauses and often times give rights that cannot be exercised. For example, a common practice is to tell consumers that they are given a choice as to how their personal information can be shared, but then do not explain how that choice can be exercised and do not offer the choice outside the contract. Other times firms would state that their information would not be shared, only to list several lines below that it might be shared with third parties, or might be shared with user consent--but it was never clear whether choice was opt-in or opt-out, or even a choice. The legal interpretation of these clauses is complex, as many are arguably deceptive, and thus not enforceable. Also, if the statement such as "we do not share your information" is considered a warranty, then a company cannot later disclaim it in the same document.
These issues aside, we graded the contracts in a strict sense. Choices that were not made clear were not counted as choices and statements that were later retracted were not counted as affirmations of fact (even though courts would most likely interpret such retraction as against the drafter, we did not code them as choices because we wanted to document company practices).
All 49 terms are listed in Table 3, which outline the guideline requirements and document compliance for all sample firms. The first column lists the terms that comprise all guidelines. The terms fall under a particular category: Notice, Sharing, User Control, Security, Data Protection, Enforcement, and Privacy by Design. The second column reports scores for all terms across all sample terms, revealing current information privacy practices.
The first 21 terms relate to the principle of notice, whose objective is to inform individuals about the information practices of the firms to allow consumers to make informed choices. The first couple of terms describe the extent to which notice of the policy is prominent (as encouraged by the FTC51). The second column shows that while
51 CITE
22

most companies make their privacy policies available on their main page, only 18% require users to expressly agree to them. While this goes against the directive to make policies salient, this distinction might not matter. Clickwraps tend to be ignored, anyway, at least when it comes to software contracts.52 I also measure the extent to which firms embraced the FTC's 2012 recommendation that privacy policies include short, or "layered" notices, summarizing the most important terms of the policies (N3) and shows that the practice hasn't picked up yet, as only 22% of contracts include one. The next series of terms in this category report the extent to which firms disclose which types of data they collect and whether they collect it.
Collection is pervasive. The overwhelming majority report they collect contact, computer (IP address, etc.) and interactive (browsing behavior, search history, etc.) information. Only a small percentage of firms explicitly state that they do not collect contact (3%), computer (2%), interactive (12%), financial (2%), and content (16%) information. A notable exception is that 40% of firms explicitly state that they do not collect sensitive information, perhaps due to the influence of the EU Data Privacy directive, which treats sensitive information differently. About a third of firms fail to disclose their collection practices. Silence is problematic because it is unclear whether firms are allowed to engage in particular behaviors if they don't disclose them. 53 Moreover, a number of terms reveal that most firms have failed to impose constraints on their data collection practices, such as collecting personally identifiable information (PII) only for internal (N12) or context specific purposes (N13).54
Like collection, sharing is also extensive. Sixty-two percent allow third parties to track user behavior (N15) and only 14% explicitly states they do not allow third party tracking. The remaining firms do not disclose whether they do or not. Here, too, notice is
52 See Bakos, Marotta-Wurgler, & Trossen, Does Anyone Read the Fine Print? Consumer Attention to Standard Form Contract, Journal of Legal Studies (2014). 53 Until very recently, the FTC has only gone after firms that violated explicit statements in their privacy policies, leaving room to conclude that undisclosed information practices are allowed unless they are unfair and deceptive in other ways. In a recent case, however, the FTC stated that a company that suffered two data breaches had a duty to provide reasonable security measures. See Wyndham case [FTC] and See Daniel Solove & Woodrow Hartzog, The FTC and the New Common Law of Privacy, 114 Colum. L. Rev. 583 (2014) 54 For a detailed account of the role of context, See Helen Nissembaum, PRIVACY IN CONTEXT.
23

lacking. Only 9% of firms identifies recipients of sold or shared data (N16) and only 7% defines words such as "affiliates" or "third parties," if it uses them (N17).
The next category, Sharing, lists eight terms that measure sharing practices and whether firms notify users about the company's practices regarding the sharing of personal information, such as whether companies have contracts with third parties limiting the use the shared information or imposing data security commitments. Because consumers cannot monitor the behavior of third parties with respect to their personal information, the companies that share such information are in a better position to create safeguards that internalize consumer preferences (assuming such preferences embrace imposing limits on third party use of their information). Yet only 13% of sample firms claim that affiliates and subsidiaries with which they share information (SH1), and 20% of contractors, are bound by their privacy policy (SH2).
A number of information practice guidelines have encouraged firms give consumers choice and control in regards to the sharing of their personal information. But choice as to information sharing is mostly illusory. Twenty six percent of all firms give consumers the option to opt-in to share information (SH8), a mechanism that is generally regarded as consumer-friendly, and 7% have offer an opt-out mechanism. The remainder doesn't give the option or not disclose. Four terms examining the degree of choice and control, such as whether they can access and correct their information (UC2), are listed under the User Control category. I find that 57% of firms give users the ability to adjust their privacy settings. Sixty six of sample firms allow users to access and correct personal information (and 6% give only access). This high percentage is likely not representative of the whole population of privacy policies. Most of the firms in markets selected for this study allow users enter and revise their information on an ongoing basis due to the nature of the services offered. Only 2% of firms offer consumers a choice as to what happens to their personal information if the company is sold of goes bankrupt (UC4).
The next seven terms relate to the category entitled Security that report on company measures to protect data accuracy and security. Despite the increased attention to security breaches, most polices do not address data security in a complete way (even though they might have implemented reasonable practices). About a third of firms state that they adopt reasonable procedures to ensure data accuracy (SEC2), and only 2%
24

guarantee it (SEC1). As would be expected, most firms will reserve the right to disclose personal information to comply with, protect a crime, or defend its own rights. Three percent state that they will disclose personal information to the government upon request. A healthier number of firms (almost have) claims to have protections incorporated into operating procedures (SEC6), such as limiting the number of employees with access to the data. Finally, 46% of sample firms identify means of technological security, such as encryption (SEC 7).
The three terms listed under Data Practices measure whether firms implement data practice measures. These are barely complied. Only 6% of sites state a period for data retention (DP1) and only 1% promises to destroy the personal data when the user terminates the account (DP3).
The final class of terms relates to Enforcement. The vast majority, or 95%, include contact information where consumers can reach out with privacy questions or concerns (E1). Finally, two terms measure whether firms adopt Privacy by Design measures, as outlined in the FTC 2012 report, only 13% of companies state that they conduct periodic compliance reviews of data and security measures (PBD1) (a result mostly driven by cloud computing firms, where 43% claim to do so). Also, only 5% of sample firms (and 29% of cloud computing firms) contain self-reporting measures in case of privacy violations (PBD2).
The remaining columns display the degree to which the terms comply with the privacy guidelines, but select only those terms that are relevant for each of the five guidelines or Safe Harbor Agreement and measures the percentage of firms comply with that particular terms. Consider, for example, the FTC FIPs 2000. The terms that comprise this particular benchmark appear on the fifth column on Table 3. For the Notice principle, we see that firms must disclose whether they collect particular types of personal information. These are 16 of the 21 terms under this category. We can also see the extent to which each term that comprises each benchmark complies with the stated requirement. Going back to terms under Notice, we see that all firms comply in disclosing whether they collect contact information (N4), and 72% comply in disclosing whether financial information is collected (N7).
25

Because the terms I measure are those that generally appear in privacy polices do not always fit the principles of all guidelines well and because some terms included in the principles may be missing, the results should be interpreted as approximations. Still, they offer an informative comparison about the extent to which firms roughly abide by these principles as well as differences in compliance across principles.
These results can be better seen in Table 4, which reports the number of contracts that comply with each of the guidelines, laws, and safe harbor agreements. The first column lists the fraction of terms within that set of guidelines that comply with the requirements or recommendations set forth therein. The remaining columns list all guidelines. For example, the HEW FIPs of 1973 is comprised of 24 out of the 49 terms that I track. The results show that 1 out of 261 privacy policies in the sample complies with at least 80% of the terms comprising this benchmark. No contract complies with 90% or more regardless of the standard. Indeed, 125 comply with only 50 to 59 percent of the original, more rigorous, FIPs.
One might conclude that the reason that compliance with the original guidelines is low is because firms have focused on the later, and perhaps more relevant, FTC guidelines. Yet this is not the case, as the degree of compliance here follows a similar pattern. While some commentators claim that self-regulation became more effective over time because more firms adopted privacy policies, the results here show that firms have become less likely to comply with the FTC recommendations regarding the information disclosure in privacy policies as well as some privacy information practices over time. Whereas 192 of all firms comply with 50% or more of the FTC 2000 guidelines, only 66 of firms achieve the same level of compliance for the 2012 guidelines. One explanation is that the 2012 guidelines add more substantive protections, making it harder to comply.
Compliance with the White House Bill of Rights is even scarcer. In this case most firms comply with 39% or less of its requirements. In conclusion, to the extent that this methodology is able to give a general flavor of compliance, the results suggest that the guidelines had only modest influence in the contracting behavior of online firms in the sample markets.
Compare the US-EU Safe Harbor, which has more teeth, because it requires firms that adhere to it to comply with their guidelines or face FTC enforcement actions for
26

failure to comply. The results show that even with the threat of sanctions, companies don't abide to the Safe Harbor as strongly as expected. The numbers in brackets show the compliance fraction for firms that claim to adhere to the US-EU Safe Harbor. Only 12 firms comply with 50 to 59 percent of terms that comprise the safe harbor, and the remaining firms have lower compliance rates. To the extent that the benchmarks constructed in this paper reflect the actual requirements. All of the companies that adhere to the Safe Harbor, which include large firms, are thus violating parts of it. It appears that even stricter standards are not enough to encourage firms to adopt them.
D. Compliance by Market
I now turn to a more focused analysis of compliance with the FTC 2012 guidelines. Table 5 shows the average rates of compliance with this standard by market. To facilitate comparison, cells are coded green when policies from that market are significantly more compliant than average. Cells are coded red when policies are significantly less compliant than average.
The differences across markets are striking. For adult sites, more than two-thirds of notice terms are compliant with FTC 2012 guidelines, but in no other market is the rate of term compliance more than half. (Recall that statistical significance is a function of sample sizes, so although message boards and gaming sites both have the same low level of compliance, the difference versus the average is statistically significant only in message boards.)
Adult sites are even more exceptional in their compliance with sharing guidelines. More than two-thirds of their sharing-related terms are compliant, while in other markets the rate of compliance is around one third or even less. We will switch from an analysis of compliance to one of substance later, but Table 3 indicates that to be compliant with sharing terms generally means limited sharing of information, and this turns out to be the case with adult sites.
The most noteworthy results in the remainder of the table involve cloud computing. Cloud policies comply with FTC data security and security-related guidelines to a far greater degree than other markets. This is intuitive, given the nature of the
27

business of cloud computing and storage. A last impression from Table 5 is the weak compliance of message boards. Their policies tend to be less compliant than average for almost every term category.
In the final row I compute the average frequency of compliance across all terms to give an overall picture. Only adult site policies comply with more than half of the FTC 2012 guidelines (53%), and cloud computing policies comply with 45%. Other markets have lower rates of compliance. When we turn to an analysis of substance, we will dig in to these differences.
E. Within-Market Effects on Compliance
Table 6 documents relationships between rates of compliance and product and contract characteristics. One of the largest effects in the table is nonprofits' 20% higher rate of compliance on sharing terms. This may reflect the fact that such sites have no business pressure to sell information to other firms. There are only scattered relationships between compliance measures and public versus private status, paid versus unpaid products, and site popularity. The strong links between certifications and actual compliance are not surprising.
There is no evidence that policies are becoming more compliant over time. There is actually a hint that more recently-updated policies are less likely to comply with FTC guidelines. This is true in all but one term category and statistically significant for overall compliance. Finally, longer contracts are generally more compliant than shorter ones, except with respect to sharing and particularly enforcement provisions. In fact, in our taxonomy, the FTC's main enforcement-related requirement is not to disclaim liability for security measures. Apparently, the longer the contract, the more likely this disclaimer is to appear, all else equal.
For parsimony I do not report the market fixed effects, but the high F-statistics indicates that cross-market differences remain after controlling for these factors. The differences remain roughly as large as those in Table 5. In other words, these factors cannot explain the cross-market differences in compliance rates, but they do add a bit of explanatory power for some terms.
28

V. Privacy Protections
Although the 2012 FTC privacy guidelines implement substantive practices, the Notice and Choice regulatory model is mostly a model about disclosure of practices and presenting options and is less about what those practices actually are. I now turn to this "substantive" question.
To understand the actual protections afforded the consumer one needs to determine what the pro-privacy term really looks like. Fortunately, for most terms this is not difficult. Privacy means giving notice various practices, and, with respect to the substance of those practices, generally minimize the information collected about the user, minimize data sharing with other parties, maximize user access to the data that are collected, feature strict security measures, and the like.
The first column of Table 7 lists the pro-privacy position for any given term. The second column, which is consistent with Table 3, shows the fraction of all policies that take that position. In cases where a policy does not disclose its practice, I make the conservative assumption that it is not the pro-privacy practice.
To facilitate comparison across markets, cells are coded green when policies from that market are more pro-privacy than average to a statistically significant degree. Cells are coded red when policies are significantly less pro-privacy than average.
The colors make it immediately obvious that adult sites present exceptionally good notice terms. By a wide margin, adult sites store less financial or site usage data (N7, N8), are much more likely to limit the use of PII to internal and stated business purposes (N12, N13), and are much more likely to prohibit third parties from tracking user behavior through advertising (N15). This conforms to intuition about the preferences of adult site users. Dating sites, on the other hand, adopt significantly less pro-privacy notice provisions than average. This is also somewhat intuitive. The nature of a dating site is to make a personal connection; some high degree of disclosure of personal information is inherently required.
Adult sites are also exceptionally strict when it comes to sharing information with affiliates and third parties (SH4, SH5). This, too, conforms to intuition about consumer
29

preferences. Gaming sites have comparatively lax practices in terms of sharing information.
One area where adult sites appear to take a less pro-privacy stance is in the area of allowing the manipulation of privacy settings (UC1). This is somewhat unfair, however, because they tend to collect and share little data in the first place. News and reviews sites tend to limit the ability of consumers to delete or anonymize their information (UC3). This may be for a natural business purpose; anonymous reviews may be shills or less informative, whereas some users build followings and reputations for accurate reviews and create value for the site.
Not surprisingly, cloud computing policies stress their strong security features. They are considerably more likely to describe technological security measures, such as encryption (SEC7), than the policies of any other market. This makes sense given that their fundamental product is data storage. But regardless of market, what a firm does with "old data," i.e. data practices, is rarely specified.
Another intuitive pattern in cloud computing policies is their lower likelihood of disclaiming liability for failed security measures (E2). This is feasible given their stronger security precautions in general. Consumers could also view such a disclaimer as a red flag. A particularly striking market difference is apparent in the use of privacy seals and other certifications (E4). Cloud computing policies use this opportunity to emphasize privacy and security. Adult firms, in contrast, have completely "opted out" of the use of privacy seals and related mechanisms. Despite their overall stricter privacy policies, adult sites appear not to value, or to think their consumers value, such certifications, and prefer to explain their privacy policies themselves.
Privacy by design terms are once again consistent with the importance of data security to cloud computing firms. Other markets' policies rarely indicate a practice of periodic, formal reviews of security measures (PBD1) or make any pledge to report privacy violations to a third party (PBD2).
A. A Privacy Protection Index
30

While a number of intuitive patterns emerge in Table 7, it is easy to lose the forest for the trees. Here I develop an overall index of privacy practices. An important issue is how to "weigh" each term. Which trees are most important? There are dozens of terms implicated in the five standards outlined in Table 3. Some are more important to the consumer than others. Rather than take a subjective approach, I measure the importance of each term based on the degree of attention paid to it across standards. In particular, I assume that terms that are implicated in, for example, three standards are less important than those noted in five standards but more important than those noted in only one standard.
For example, whether the company adapts reasonable protections to ensure data security (SEC2) is an issue specifically addressed by all five standards, and whether the company shares PII with third parties (SH5) is directly addressed by four of the five standards. But whether a policy provides a link to the FTC's Consumer Complaint Form or its telephone number (E3) is far less crucial to the consumer and is addressed in only one standard. The index therefore gives five times as much weight to the substance of SEC2 and four times as much weight to SH5 as it does to E3. While not perfect, the idea of giving more weight to terms that have been the subject of more regulatory attention is intuitive and has the benefit of objectivity.
Specifically, I score each term 0 or 1 according to whether it takes the pro-privacy stance expressed in Table 7. I then take a weighted average of these scores using the frequency of regulatory attention as the weights. In this manner, I compute a privacy protection index for each category of terms and a score for the overall policy. The index ranges from a minimum of 0, for a policy that avoids the pro-privacy position in every case, to a maximum of 1, for a policy that always takes the pro-privacy position. (In practice, these extremes are never seen.)
Table 8 shows the average indices for each market and each category of terms. The impressions from Table 7 appear clearly here. Adult sites are relatively strong in terms of notice and data sharing, and have the highest overall privacy protection index by a nontrivial amount. Cloud computing comes in second overall, owing to their strength on security-related terms, as noted above. The overall scores for other markets are similar. Figures 1 and 2 show the full distributions for the notice and overall protection indices.
31

B. Within-Market Effects on Protection.
Similar to the regression analysis of compliance, I explore the associations between privacy protections and other factors in Table 9. Each column shows the results of a regression of the level of privacy protections, calculated using the methodology above, on various company and product characteristics as well as market fixed effects.
There are few robust relationships between privacy protections and nonprofit status, public versus private, or paid versus unpaid services. Popular sites, as measured by Alexa, tend to have more pro-privacy policies. A one-standard deviation increase in popularity is associated with a 0.02 higher protection index, which is not too large (0.005*3.92 = 0.02). Firms that claim certifications do have better actual practices, as one would expect.55
Policies that have been updated more recently tend to have slightly lower protections. Firms whose policies were last updated in 2014 have overall protection indices that are, on average, 0.018 lower (-0.009*2 = 0.018) than those last touched in 2012. This is stronger or weaker depending on the category of term, but there is clearly no trend toward increased privacy protections.
The length of the policy has strong relationships with protections, but the direction depends on the category of term. The effects are sometimes large. The standard deviation of the log number of words is 0.81 (unreported), and a one-standard deviation higher log number of words, e.g. a length difference of 1700 vs. 3500, is associated with 0.095 lower sharing protections (-0.117*0.81 = 0.095). Perhaps firms that share PII actively think it wise to explain their practices at length to prevent surprises or litigation.
As in Table 6, I do not report the market fixed effects, but the high F-statistics indicates that cross-market differences remain after controlling for these factors. The differences remain roughly as large as those in Table 8.
VI. Conclusion and Implications
55 The large effect (0.355) on enforcement-related protections is mechanical. Certifications are part of the definition of enforcement (E4).
32

Debates regarding the regulation of information privacy are popular and frequent and policymakers are constantly considering whether the current regulatory model of consumer information protection should be revised or whether bounds should be placed on firms' information practices. This paper contributes to the existing literature and these debates by conducting a comprehensive large-sample analysis of online privacy policies. I review 261 privacy policies for services where privacy concerns are especially significant, including social networking and cloud computing. I study the incidence of 49 terms pertaining to notice, data sharing, enforcement, security, and other features and I contrast them with the current guidelines. Next, I compare differences in privacy protections across and within seven markets to explore the possibility of market effects by examining compliance and information privacy protection across markets. The analysis uncovers a number of new facts about privacy policies to help inform both academic and regulatory discussions.
What does the evidence imply for the efficacy of the standard Notice and Choice regulatory model? The general assessment is not favorable. Policies are long, complex, incomplete, and often silent on important subject matters. Moreover, the substance of the rights that are explicitly reserved are sometimes fairly concerning. Policies that claim compliance with various regulatory benchmarks inevitably omit or contradict features of those benchmarks. These features make difficult or almost impossible for consumers to read and for intermediaries to simplify the terms in a way that consumers can understand. It's just very hard to get a clear meaning from them. A possible amelioration of this problem would be to require standardization of particular disclosures, but such approach would not correct for any consumer limitations in acquiring and using this information in welfare maximizing way.
That being said, striking differences appear across markets and firm characteristics. Adult and cloud computing sites offer more meaningful protections in the area of notice, collection, sharing, and security (for adult) and data security and substantive data protections (for cloud computing). These differences are consistent with intuitions on what one expect consumers to especially care about when dealing with such sites.
33

Of course, many of these differences are likely attributed to differences in the business model or the product or service offered across markets(after all, cloud computing is in the business of keeping user information secure and in the cloud), but all firms can potentially benefit from some forms of secondary uses of data sharing or save costs on security protection. While these results can't speak to whether consumers pay special attention to particular information practices, they suggest that sellers (to the extent they are comparable) act as if consumers do. The implication is that proposed solutions might need to be more nuanced and take into consideration the information privacy practices and firm incentives within each particular markets.
34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

